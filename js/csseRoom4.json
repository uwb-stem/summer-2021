{
    "csse": [
        {
            "time": "12:30 PM - 12:45 PM",
            "projectId": "csse-4-1230",
            "title": "Recalling Messages for the Alexa App",
            "studentName": "Gabriela De Vincenzo",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Amazon",
            "facultyAdvisor": "Dr. Laurie Anderson",
            "posterLink": "./posters/csse/vincenzo_gabriela.png",
            "abstract": "During my internship at Amazon, I worked as part of the Alexa Sharing team. The project I was assigned was to implement message recalling for all types of messages. Users will be able to press and hold on any message, and after confirming their intent in a pop-up, that message will be replaced with a text message that states ‘This message has been recalled.’\n\nCurrently, through Alexa, several types of content can be shared: texts, voice memos, photos, music, and shopping lists. However, once sent, these messages are permanent, creating the need for a recall message feature.\n\nAfter working on this project for the summer, recalling messages is functional on test android devices. The API created for this feature is already public and accessible, and the main feature will be released after IOS development and quality assurance.\n\nThis project’s significance is found in its impact on Amazon’s customers. Now, customers will have the capability of recalling messages that they sent by mistake or that are no longer needed. Considering that there are 40 million Alexa users in the US alone, it is clear that this project will have a wide impact by allowing all Amazon customers to delete messages in their Alexa app."        
        },
        {
            "time": "12:45 PM - 1:00 PM",
            "projectId": "csse-4-1245",
            "title": "Software Implementation of Admin Comparison Feature",
            "studentName": "Janelle Dockter",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Microsoft",
            "facultyAdvisor": "Dr. Laurie Anderson",
            "posterLink": "./posters/csse/dockter_janelle.jpg",
            "abstract": "The main goal of my internship on the Intune team at Microsoft Azure was to implement a crowdsourced comparison feature for admins, making the deployment of policies more accessible. To achieve this, I first had to become familiar with Intune’s codebase.\n\n One outstanding problem with Intune’s user experience was targeted app configurations. If users wanted to adjust these settings, they needed to understand key-value pairs, since there was no graphical interface for the targeted app configurations. I developed the user interface for Outlook’s TAC settings, allowing the admins to configure their desired settings more comfortably. This task also aided in my understanding of the development process Azure’s coders follow.\n\nAfter I understood the pre-existing code within Intune, it became apparent that the blade that would hold the comparison feature had not yet been migrated to no-PDL yet, so any code I wrote would have been would have been rewritten. To address this problem, I rewrote the overview blade in TypeScript, which provided a stable location for implementation of the comparison feature.\n\nOnce I had a no-PDL blade to build on, I implemented the overview comparison feature on the overview blade. This averaged data from settings in three different categories - data protection, access regulation, and conditional launch - to display the admin’s protection levels compared to the crowdsourced baseline. I also implemented an inline comparison feature on the DP, AR, and CL blades, which displayed the most selected option for each setting compared this to the current option that the admin had selected.\n\nThroughout the internship, I encountered problems such as developed code not compatible with the restrictions of the Ibiza framework and controls that were available in PDL not accessible in TypeScript. Despite these setbacks, the comparison feature was implemented, and tested, bringing Intune closer to helping their admins and providing them with useful tools for their Azure licenses."        
        },
        {
            "time": "1:00 PM - 1:15 PM",
            "projectId": "csse-4-100",
            "title": "Decommissioning Legacy Firewalls and Load Balancers",
            "studentName": "Joshua Sterner",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - T-Mobile",
            "facultyAdvisor": "Dr. Afra Mashhadi",
            "posterLink": "./posters/csse/sterner_joshua.png",
            "abstract": "The merger between Sprint and T-Mobile resulted in duplicate efforts and systems in the new T-Mobile. Transitioning of network traffic from the legacy Sprint network to the new T-Mobile network is being undertaken to unify the new T-Mobile network and eliminate unnecessary duplication. As a result of this, many of the legacy Sprint firewalls and load-balancers are seeing decreasing traffic. The goal of this project is to identify the firewalls and load-balancers which are ready to be decommissioned, verify that they no longer carry any valid traffic, and complete the decommissioning of these systems.\n\nAs a part of this project, I developed an object-oriented framework for concurrently running commands on device clusters and processing the output of those commands. I chose this approach since there were multiple types of devices to decommission, and separation of device-specific concerns from common functionality enables this software to be easily extendable and testable. I also identified session classification criteria to classify sessions from Juniper MX960 and Juniper SRX series firewalls to determine if sessions are valid, invalid, or otherwise of-interest. Furthermore, I developed criteria to classify the decommissioning readiness of the Juniper MX960 firewall clusters and Juniper SRX series firewall clusters.\n\nAs a result of this work, I have identified fifty Juniper MX960s which are ready to be decommissioned. I have also determined that most of the Juniper SRX clusters are still carrying valid traffic and have identified Juniper SRX clusters of interest. This work will have notable impact in that it will save energy costs, free up rack space, and save maintenance and support costs."        
        },
        {
            "time": "1:15 PM - 1:30 PM",
            "projectId": "csse-4-115",
            "title": "Social Sharing on Pandora",
            "studentName": "Noah Reiniger",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Pandora",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/reiniger_noah.png",
            "abstract": "Pandora is a music streaming service owned by SiriusXM that focuses on recommending users new songs. This process is based on the “Music Genome Project” which classifies the musical traits of the songs that the user has listened to and recommending songs with similar traits. During my internship, I worked with the Android Engineering team with the UI squad.\n\nThe project I worked on is to add social sharing to their mobile android application. This means the app is now able to share songs, albums, playlists, and artists through various apps like Snapchat, Instagram, Facebook, and more. Users are also able to share these things through links. This feature has been integrated using the social media platform’s SDKs and be directly sharable to things like Stories on Snapchat and Instagram.\n\nWhile working on this project, I worked with one other intern on my team and with several other interns who were working on their perspective platforms to ensure a standardized experience between platforms. A large portion of this project was completed during our internship on the Android side, including creating a mock UI interface and the integration of the sharing for each of the platforms.\n\nThis project will benefit the company in that it offers new ways of getting new users, re-engaging idle users, and enhancing the experience for current users. It also lets us know how our users share our media so that we can better cater to our experience."        
        },
        {
            "time": "1:30 PM - 1:45 PM",
            "projectId": "csse-4-130",
            "title": "A Scaled Adventure An Exploration of AR Using ASL",
            "studentName": "Grace Nelson",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/nelson_grace.png",
            "abstract": "The Augmented Space Library (ASL) was developed by students in the Cross Reality Collaboration Sandbox (CRCS) research group to allow users on Augmented Reality (AR) enabled mobile phones and Computers to connect and interact in the same cross reality space where virtual and physical worlds are integrated. This research is an exploration into how that functionality could be applied to more complex applications and to discover where ASL needs more development.\n\n  “A Scaled Adventure” was created centered around the ASL library’s existing functionalities. These functionalities include networked connections, moving, adding, removing, and changing objects through both the PC and AR clients. This served to identify areas where the ASL library excels as well as any additional functionalities that should be added or improved to both facilitate development and to expand the kinds of development that are possible.\n\n The core function of “A Scaled Adventure” is comparable to that of a mini game. The PC person is spawned as a small avatar on a plane in the real world and runs around trying to collect mushrooms. The AR person is the eye in the sky, destroying obstacles and marking where the mushrooms are. The PC person cannot see the mushrooms, so communication and collaboration are crucial to beat the game with a fast time. The AR person can also damage or kill the PC player, build bridges, and clear the way depending on the kind of game play the users desire.\n\nDeveloping this application helped clearly outline the strengths and weaknesses of the ASL library. While the ASL library can clearly be used to create interactive applications there are still a few areas that could be improved. For Example: Currently there are only a limited number of actions that can be performed on a network shared object (Transforms, Rotations, Float Arrays, etc.) this means that Unity physics and other object attributes must be set in creative ways. Using this research, the CRSC can make these improvements and develop ASL into an even more expansive AR development tool. This application also stands as a shining example of the kinds of AR apps that students can create using the ASL library and aims to inspire some to brave this kind of development themselves."        
        },
        {
            "time": "1:45 PM - 2:00 PM",
            "projectId": "csse-4-145",
            "title": "Topographical Map - Route Display",
            "studentName": "Nicholas Soerens",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/soerens_nicholas.png",
            "abstract": "Project entails the development of a topographical map display, specifically the display of a user-defined route between maps depicting the same space, as part of a larger group project. This route consists of a straight-drawn route, which directly connects user-defined points, and a curved route defined by the topography (curvature) of the map being acted upon.\n\nThis display includes a scale line, which displays a predefined distance in meters and in feet, to give a sense of the size of the maps. The distance is locked to the predefined Unity unit of 1 unit = 1 meter. Additionally, scaling does not provide “round” numbers for display in all circumstances.\n\nUsers can add markers (points) to their list, either by clicking on the map directly or by clicking and dragging from an existing marker. Additionally, users can remove any existing marker, regardless of who placed the marker originally.\n\nRoute development requires user testing to ensure accuracy of placement and deletion, in addition to fixing issues regarding marker deletion. Further optimizations to the route display—specifically the curved route, in terms of object count—could improve program performance. Additional work is also required to bring route functionality in line with more recent additions to map manipulation.\n\nAbstraction of display functions to work properly, regardless of whether the user makes use of just a personal computer (PC), or if the user is connected to a virtual reality (VR) headset. Abstraction is performed to reduce overhead when a user switched between PC and VR.\n\nAbstraction of all major PC features is not yet complete, as all map brush functionality has not been integrated into the code interface. Currently, some duplicate scripts are required for a VR user to maintain consistency with a PC user performing the same actions.\n\nThis project was undertaken to explore the potential for remote collaboration in a virtual space. Collaboration is facilitated via the Augmented Space Library (ASL) and the Unity engine. All design, prototyping, and testing was student-directed.\n\n The topographical map display may be further developed and allow users to explore part of a real-world space. This space may be utilized for recreational use, such as planning out a hiking trail; alternatively, emergency response teams may use the map functionality as a response to natural disasters, such as wildfires or landslides."        
        },
        {
            "time": "2:00 PM - 2:15 PM",
            "projectId": "csse-4-200",
            "title": "Internship at BusySquirrels",
            "studentName": "Arun Sarma",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - BusySquirrels",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/sarma_arun.png",
            "abstract": "BusySquirrels is a startup focusing on delivering cashback offerings and cross-store price comparison to online shoppers at supported stores. To do this, they have a website and Google Chrome extension which are powered by a cloud backend.\n\nAs a Software Engineer intern at BusySquirrels, I worked on developing web crawlers, using backend cloud services on Amazon Web Services (AWS), productionizing Machine Learning models, and creating an Android application which utilizes their backend to deliver cashback rewards to customers. My assignments allowed me to use various technologies and develop code in different environments within their system. In addition, we had standups every two days where I could present my work and discuss any issues with my mentor and fellow interns.\n\nI used Python to create web crawlers which scraped product information from online stores to be used later in machine learning models and on their website. I could use my prior knowledge of Scrapy, and I learned a lot more about more advanced tools used to scrape more complex websites. Next, I chose to take on an AWS assignment where I had to implement AWS Redis caching into their existing web-based application. I learned about how their web-based application operates to deliver content to customers. Later in the internship, I focused on Machine Learning, where I had to evaluate and contribute to a model developed by fellow interns. This model’s purpose was to predict if two of the same products from different stores where similar based on their name, description, and image. In this experience, I got more familiar with various Python libraries and how to use APIs to build training and testing sets from real-world data quickly. I also learned about Computer Vision while exploring how two images can be compared for similarity.\n\n Towards the end of my internship, I was challenged with building an application which would notify users of certain cashback offers if they are using a supported shopping app or website. After researching, I found a way to satisfy the requirement, and I presented a proof-of-concept application to my mentor. I started developing the minimum viable product after discussing the requirements in more detail. During the development process, I gave demos, took feedback from my colleagues, and published releases to Google Play and the Amazon App Store. This experience allowed me to lead a project from its inception and publish an application which is used by customers."        
        },
        {
            "time": "2:15 PM - 2:30 PM",
            "projectId": "csse-4-215",
            "title": "Amazon FireTV Telemetry: Monitoring Data Quality",
            "studentName": "Aniley Sabi",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Amazon",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/sabi_aniley.jpg",
            "abstract": "Amazon Fire Tv Telemetry team is part of Amazon’s Device Organization. The Device Organization has sub teams that control different devices like Alexa, Kindle, Echo, FireTv etc. Fire Tv Telemetry team specifically controls the Fire Tv device. Fire Tv device is a video streaming device that allows you to play 4K and HDR content on your 4K TV. It comes with a remote plus a tiny cable that plugs into your TV’s HDMI port. Fire TV products are designed to provide customers with an interactive experience of enjoying various video streaming services.\n\n To understand better and evaluate customer behaviors, Fire TV Telemetry team collects and processes raw customer behavior logs from Fire TV device. In this case, the quality of customer event logs is very important for Fire TV Telemetry teams to accurately assess whether the video streaming services that the team recommends can meet customer needs. However, currently, the team has very little insight into the quality of those customer event data.\n\nFire TV Telemetry team collects and processes raw customer behavior logs from Fire TV device, storing them in augmented event (a raw customer events log database) and some in curated dataset (an organized customer events log dataset). However, sometimes these customer behavior event logs undesirably contain bad data quality, which can decrease the accuracy of data and the video services recommendations for customers.\n\n As a software engineer intern, my responsibility was to design a data monitoring spark job to evaluate the data quality of customer event logs received from Fire TV devices. The evaluation process consists of creating Java Spark Jobs that captures bad data. For example, the customer event logs are JSON files, and sometimes the field name and value don’t match or the JSON file’s schema is not correct.\n\n One of my additional responsibilities was to monitor how the quality of the data improves/degrades overtime by creating report metrics. This is done by writing Java Spark Jobs that takes bad data stored in a dataset as an input and creates metrics such as the number of different unknown_attribute, invalid_type, invalid_enum and etc. that are generated by this application in an hour."        
        },
        {
            "time": "2:30 PM - 2:45 PM",
            "projectId": "csse-4-230",
            "title": "Medical Device Software Engineering Internship",
            "studentName": "Mariana Huynh",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Verathon",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/huynh_mariana.jpg",
            "abstract": "Disclaimer: I did sign a Non-Disclosure Agreement with the company I interned for so I will only be discussing what I did and learned at the high level only.\n\n As a Software Engineering Intern on the Research and Development team at Verathon Incorporated, I work in the Imaging and Scanning Solutions department. My primary task is to develop solutions to medical device problems. Verathon currently has two products out for release: the BladderScan and the GlideScope. The BladderScan is used for measuring volume in the bladder and the GlideScope is used for scanning the larynx. For the duration of my internship, I worked on the BladderScan ultrasound imaging application and provided support in developing prototypes for medical device based on embedded systems technology.\n\n For the duration of the internship, I was introduced to and worked with industry tools for agile software development, developed solutions for medical device issues, implemented new features for the medical device, and attended various meetings on a daily basis such as scrum meetings and merge request code reviews. For agile development, the team at Verathon uses Jira for managing the Scrum team. Tickets for work are written in the form of user stories and then assigned to team members during each two-week sprint using Jira. To manage the code base, the development team uses GitLab. This is also where code reviews were conducted in conjunction with Microsoft Teams video meetings. This combination worked very well since about half the team was remote and half were in person.\n\n As for the programming work I was assigned, I worked in various areas of the legacy code base. I worked with parts of the operating system for the medical device, the user interface for the medical device console, and with how the console stored data to name a few. It was very fulfilling working with embedded systems. Getting to develop, test, and run my code onto the console and see the changes I made physically was rewarding. The physical aspect of interacting with the console was particularly interesting for me.\n\n Overall, the internship has been very engaging; I have learned something new every day and gain knowledge on how software developers work in industry. The code that I write has an impact on the medical device console. Taking part in Verathon’s passion to empower healthcare providers and extending the lives of patients is work that I am proud of. I am very thankful of the opportunity I was given at Verathon and I hope to continue to learn more about embedded systems in the medical device industry."        
        },
        {
            "time": "2:45 PM - 3:00 PM",
            "projectId": "csse-4-245",
            "title": "Neural Network Actor Recognizer Application",
            "studentName": "Ira Yago",
            "studentMajor": "CSSE",
            "projectType": "Individual Project - Student Defined",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/yago_ira.png",
            "abstract": "The goal of this project was to develop a system that enables users to use machine learning for recognizing actors in images and videos. This system is intended to aid fans of movie stars with recognizing them in movies and images that they appear in.\n\n My approach on creating this system consisted of developing an application in Matlab that utilizes deep learning to achieve my project’s goal. I decided to use Matlab for developing this application because I wanted to use the GoogLeNet CNN architecture in addition to Matlab’s Deep Learning Toolbox. Programming the app’s front-end and back-end could be done all in Matlab as well.\n\n In order for GoogLeNet to train on human faces, I had to replace the current feature learner and classification output layers since the CNN was pretrained. With GoogLeNet’s new layers, I locally trained the CNN with image datasets that were split into 70% training and 30% validation sets. My application then uses this trained CNN model to predict which actor is in an image or frame of a video and displays the name and accuracy to the user.\n\n  The end result of this project is an application that helps users train, test, analyze, and reuse CNN models. However, the CNN models that I have trained are not as accurate as I wanted them to be since I only trained with less than a hundred images per label. To increase the accuracy of predictions, I performed augmentation on the training datasets to prevent overfitting and collected negative samples for training.\n\n  The significance of this application is that it lets users create and maintain their CNN models all in one place. The user is able to preprocess their dataset and can immediately start training on it, along with being able to track training progress. Users can then test their model on any video or image that they upload to the app. More freedom and efficiency of how users create their models can be added in the future in the form of customizable augmentation options and collection of data in-app."        
        },
        {
            "time": "3:00 PM - 3:15 PM",
            "projectId": "csse-4-300",
            "title": "MessagesApp",
            "studentName": "Karan Gill",
            "studentMajor": "CSSE",
            "projectType": "Individual Project - Student Defined",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/gill_karan.png",
            "abstract": "The purpose of this capstone project was to learn about web development technologies and get hands-on experience with building a real-world web application. For this project, I chose to build a messaging application because it allowed me to incorporate a lot of technologies and design principles that I’ve learned at the University of Washington Bothell. Some of these principles include combining authentication, authorization, database, algorithms, user-centric design, etc. into a single tangible application.\n\nThis project was developed with HTML, CSS, and the React JavaScript library for the front end and incorporated Google’s Firebase for authentication and Google Firestore’s real-time database for the back end. The project development was completed using agile methodology to incrementally add new features and iteratively improve existing functionality. User feedback was gathered in the testing phase of the application in order to find and fix bugs, improve existing functionality, and add new features. The end result of the project is a functioning web application that allows users to register/sign in to the application and find other users via their email address in order to send and receive text messages in real-time."        
        },
        {
            "time": "3:15 PM - 3:30 PM",
            "projectId": "csse-4-315",
            "title": "Fakeology - A Fake Review Detection Web Application for Amazon Products",
            "studentName": "Zach Shim",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Min Chen",
            "posterLink": "./posters/csse/shim_zach.jpg",
            "abstract": "Product reviews on web-based shopping sites have become a vital asset for online consumers. The reviews of a product can significantly sway an individual’s opinion about a product. Therefore, malicious sellers will deliberately manipulate reviews on their products to sway the opinions of potential buyers. Machine learning models can be leveraged against spammed or ingenuous reviews through pattern detection and analysis.\n\nThe faculty research I worked on involved scaling a legacy project that detects fake reviews from Amazon. A collection of data analysis algorithms worked in tandem to form a classification system that takes the text of a review and basic information about its reviewer as input and outputs a ‘fakeness’ score that indicates a product’s credibility. The system uses three methods for analysis: detection of duplicate reviews, detection of incentivized reviews, and detection of anomalous reviews.\n\n I expanded on this existing framework to make the system web based, more efficient, and easier to scale. The product was a website with a refined web interface that allows users to dynamically analyze new data by pasting links to an Amazon product’s webpage. The system then scrapes relevant data from the product page and feeds this information into pre-trained machine learning models for analysis. The pipeline of the link pasting page follows a similar structure to the original methods of analysis: similarity detection, sentiment detection, and anomaly detection.\n\n I experimented with a number of different libraries and machine learning models. I used an unsupervised model for similarity detection, which featured a mix of natural language processing, TFIDF vectorization, and latent semantic indexing. A cosine similarity heuristic was used to determine the similarity between all pairwise vectors in the corpus.\n\n This application can be a useful asset to consumers that are unsure if a product’s reviews are fake. Using this application can give them confidence that their purchase is free of malicious reviews."        
        }
    ]
}