{
    "csse": [
        {
            "time": "12:30 PM - 12:45 PM",
            "projectId": "csse-3-1230",
            "title": "Critical Infrastructure Resilience & Protection",
            "studentName": "Denali Cornwell",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Idaho National Lab",
            "facultyAdvisor": "Dr. Munehiro Fukuda",
            "posterLink": "./posters/csse/cornwell_denali.png",
            "abstract": "Background:\n\nCritical infrastructure (CI) resilience and protection is central to Idaho National Laboratory’s (INL) mission as a member of the 17 national laboratories operated by the Department of Energy and Department of National and Homeland Security (N&HS). As part of N&HS at INL this summer I worked on a cloud application called All Hazards Analysis Framework (AHA, “a-ha”), which plays a key role in helping provide insight on where, how, and when to deploy and maintain CI. Within the project I specifically engineered a solution to migrate the authentication, authorization, and user management system from PostgreSQL to MongoDB. The reasons for migrating databases were that MongoDB was already being used for other datastores across the application whereas PostgreSQL was only used in this specific area so migrating databases would reduce IT complexity, and provide better maintainability/reliability for the application. I also created a script for migrating the data between PostgreSQL and MongoDB so user and role data could be easily transferred on all the deployed instances of AHA.\n\nResult:\n\nInstead of ten SQL tables for user and role related data, there are two MongoDB collections within a MongoDB database, users and roles. This means that there is only one simple possible query across collections from users to roles that describes what role a user is a part of, otherwise all user or role information can be gathered by querying for a single document in either of the collections. The document-based and schema-less model of MongoDB also allows for a simplified process of modifying what a user/role is and what data is stored with a user/role.\n\nConclusion:\n\nMigrating to MongoDB simplified the authentication, authorization, and user management of AHA and has allowed my team to easily access, change, and use user related data more easily throughout the entire application. It has also allowed us to drop PostgreSQL, decreasing IT complexity which was holding back further innovations."        
        },
        {
            "time": "12:45 PM - 1:00 PM",
            "projectId": "csse-3-1245",
            "title": "Salvo Tools",
            "studentName": "Satrya Aghra Pradana",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - PT Telekomunikasi Seluer Indonesia",
            "facultyAdvisor": "Dr. Munehiro Fukuda",
            "posterLink": "./posters/csse/pradana_satrya.jpg",
            "abstract": "The Telkomsel company ByU business project initiative of partnership with sales partners is growing rapidly, where in April 2021 there are more than 12k partners. This causes the need for a dashboard website that can monitor partner performance, manage partners & exchange sim cards. The condition of the ByU team currently does not have these tools, for management and supervision it is still done manually which takes a longer time to process. This causes the lead area to not be fast in the process of handling partner maintenance, always depending on the technical team for administrative changes, as well as reliable sources regarding partner data as there are numerous occasion of people creating different reports. The dashboard website is hoped to provide the solution to this problem.\n\nThe internship task is to develop and create the frontend website using the already provided UI design by the team’s UX designer. Using frontend technologies such as Vue.JS, Vuetify, and many more. The backend although not within my responsibilities were done in PHP Laravel Lumen for building micro-services backend and fast APIs.\n\nAt its current stage both the internship and this project has not been finished yet. It’s currently around 30-40% complete. However, this progress is within the team’s expectations and is going smoothly even with the small hiccups due to external factors.\n\n The internship causes me to develop skills and learn significantly in the frontend technologies, and experiencing the professional technology industry with its sprint methodologies and understanding the business goals and requirements."        
        },
        {
            "time": "1:00 PM - 1:15 PM",
            "projectId": "csse-3-100",
            "title": "Internship at Zipley Fiber - Facility Locates Data Analysis",
            "studentName": "Brent Barrese",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Zipley Fiber",
            "facultyAdvisor": "Dr. Munehiro Fukuda",
            "posterLink": "./posters/csse/barrese_brent.png",
            "abstract": "During the summer of 2021 I did an internship for Ziply Fiber. Ziply is an American telecommunications company that is based out of Kirkland, Washington. My primary objective during the internship was to perform data analysis around their facility locates process and identify process improvements. In addition to this goal, I also used my computer science knowledge and skills to work on current challenges they are facing.\n\nEvery year, Ziply spends millions of dollars in Washington state alone to have facility locates done. These locates are performed when customers or contractors are going to be digging in the area of buried facilities. In Ziply’s case, most of these buried facilities are copper cable and fiber optic cable. Maps are created within an engineering or GIS division, and they are updated and sent out to different organizations involved in the chain of this process. The goal of the project was to gather and process data of historical tickets, analyze the current process of mapping the facilities with current buffer zones, and identify improvements with the results. Over the internship I was able to identify and gather relevant historical data (over 140,000 tickets of data) and process the data. I then gathered the current mapping data and transformed it into what would assist me with my analysis.\n\n I primarily relied on Python to perform what I needed with code. I chose Python due to its modern capabilities, ease of use and understanding, and effective data science libraries and modules that can be incorporated, such as Pandas. I used QGIS for my geographic information system analysis application due to it being free and open source. This worked out well because QGIS supports Python scripting inside of the application to perform tasks. This showed me the capabilities and brought these 2 technologies together for me, while at the same time creating a challenge in having to research and understand the documentation.\n\n Through my work I was able to successfully identify some of the current challenges and areas for improvement. My analysis showed that tickets are being processed more than they need to, resulting in hundreds of thousands of dollars being unnecessarily spent by Ziply. I identified different buffer zones for their facilities and the associated cost savings with each."        
        },
        {
            "time": "1:15 PM - 1:30 PM",
            "projectId": "csse-3-115",
            "title": "Industrial Complex",
            "studentName": "Rosemary Rosvanis",
            "studentMajor": "CSSE",
            "projectType": "Individual Project - Student Defined",
            "facultyAdvisor": "Dr. Wooyoung Kim",
            "posterLink": "./posters/csse/rosvanis_rosemary.jpg",
            "abstract": "Mass incarceration is one of the biggest social issues facing America and has been for decades. The United States holds almost a quarter (22%) of the prison population despite the country only being 4.4% of the world’s population.\n\nMy goal with this project was to create a game that gets more and more difficult as you go on, without ever ending in a “win”. I wanted to facilitate the feeling – on a smaller scale – of being bogged down and unable to escape small mistakes that add up into larger consequences.  I accomplished this by creating a platformer that is on an infinite loop. As the player runs through the game, their health becomes depleted at a steady rate. They must collect food to increase their health and coins for their score. Throughout the level, they must avoid enemies that make them run slower and deplete their coins. The games ends when the player runs out of health. There’s no way to win the game, but rather the player is trying to get the highest score possible.\n\nTo create the game, I used the Godot game engine for development, which has it’s own code editor and scripting language, gdscript.\n\nIn conjunction with the game, I also provided research about the realities of the prison industrial complex in America and the way it affects individuals and the community as a whole. This paper is linked to in the about section of the game. Links for non-profit organizations related to the issue can also be found in the about section. To find sources for the paper, I used the UW library to search for peer reviewed sources."
        },
        {
            "time": "1:30 PM - 1:45 PM",
            "projectId": "csse-3-130",
            "title": "Software Engineer Co-op at WAVES",
            "studentName": "Mitchell Johnson",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - MSU Avida ED",
            "facultyAdvisor": "Dr. Wooyoung Kim",
            "posterLink": "./posters/csse/johnson_mitchell.png",
            "abstract": "Studying evolution helps scientists study diseases, explain natural phenomena, and many other things. Digital evolution is a simulation of organisms and their DNA in an artificial landscape that lets scientists test and run evolutionary experiments.\n\n M.A.B.E. (Modular Agent Based Evolver), It is a reconfigurable digital evolution research tool designed to aid scientists and researchers by reducing the time from hypothesis to testing. While MABE is a powerful tool, technical prerequisites make using it difficult such as a knowledge of C++ and access to a machine running linux. MABE-2 aims to fix these issues by being supported both fully on the web and on linux, as well as providing an easy-to-use graphical web interface, directly addressing the original MABE’s issues of inaccessibility. I worked on improving the linux version of MABE2.\n\n Quantifying my improvements to both accessibility and ease-of-use required a method of evaluating the difficulty that an average researcher would go through when implementing a custom experiment. Important variables in my evaluation would be both the number of steps and average time to implement an experiment, with the specific experiment being implemented being a controlled variable.\n\n Before my work on MABE2, the number of steps before any custom experiment could be run was 6 steps with an average implementation time of around 30 minutes. My new streamlining of the experiment design flow reduced the number of steps to as low as 2 steps, with a max of 3 steps and an average implementation time of around 15 minutes. Not only has the number of steps and time to test been reduced, but the level of c++ comprehension required to use it has been reduced as well.\n\n My work will save headaches and confusion to researchers and students who use MABE2 in the future, making working on digital evolution tools feasible for a much larger set of researchers, and will make designing and testing computational evolution experiments easier and faster."        
        },
        {
            "time": "1:45 PM - 2:00 PM",
            "projectId": "csse-3-145",
            "title": "Using the Nanopore for Coevolution Analysis",
            "studentName": "Donald Tran",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Wooyoung Kim",
            "posterLink": "./posters/csse/tran_donald.png",
            "abstract": "The Oxford Nanopore is a device capable of sequencing any DNA or RNA fragment length in real time. It has been used in a variety domains where complex genomic data analysis is an applicable and useful approach to the problem and it is particularly useful in research of evolution where the ability to sequence longer sequences would help illuminate the role that various mutations might play in the functioning of organisms.\n\nPreviously, Professor Kristina Linnea Hillesland’s lab had used a device called Illumina to sequence the DNA they needed for their analysis, but since it had shorter reads than the Oxford Nanopore it was unable to cover long repeating segments of DNA. To complete their analysis, they used Oxford Nanopore to sequence some of the specimens they had on their lab. Unfortunately, the data given by the device was in a format not conducive to analysis with other data the lab commonly worked with. To make the data gathered by the Oxford Nanopore useful would require further processing.\n\nThe goal of this project is to figure out the data format given by the Oxford Nanopore device and adapt and augment it such that it would be amenable to integration with data previously gathered from other sources. Additionally, a protocol for working with the Nanopore device would be established to make it more accessible to future use as well as to other scientists on campus who may want to incorporate the device into their research.\n\nThe result is a document detailing the entire Nanopore processing pipeline. It gives a complete and full understanding of Nanopore to the user and allows them to use the device effectively in their research. This will open a world of possibilities for researchers at UWB interested in sequencing data."        
        },
        {
            "time": "2:00 PM - 2:15 PM",
            "projectId": "csse-3-200",
            "title": "Visualized Data Analytic Tool for Quantitative Multiplex Coimmunoprecipitation (VIA-QMI)",
            "studentName": "Scott Mar",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Wooyoung Kim",
            "posterLink": "./posters/csse/mar_scott.jpg",
            "abstract": "This project is a continuation of the Visual Data Analytic Tools for Quantitative Multiplex Co-Immunoprecipitation (VIA-QMI) application. QMI, or quantitative multiplex co-immunoprecipitation, is a process in which protein-protein interaction levels are generated for further research. Specifically, proteins are extracted from blood samples, which are in turn probed with other proteins to view how much interaction occurs. This data is then used to design and engineer T-cells that are effective at killing cancerous cells. The VIA-QMI program assists these researchers to quickly view, visualize, analyze, and save this data. Before VIA-QMI was implemented, a mediator was required to generate the viewable results for the researchers through multiple different applications in different languages. With the creation of VIA-QMI, researchers are now able to use a single application by themselves, for faster viewing and analysis.\n\n My contribution to this project was further expanding the application’s data visualization and saving features, as well as improving the overall usability. This was done by implementing a fold change value heat map, adding/improving data export buttons, and upgrading ease of access through reworked viewing and file explorer options. These new additions allow researchers to not only visualize their data in new means, but also allows them to do so in a faster, easier process. By enhancing these sections of the project, users are able to identify significant, relevant data at a glance, while also doing so in a more straightforward and less error prone way. Future work on this project looks to expand these ideas by bringing new analysis tools that allow researchers to evaluate the data even further, with continued development for the aforementioned export and heat map features when needed. All current and future tasks of the project maintain the same end goal of providing researchers an accessible, single end-to-end application they can use to advance their work in a quick and simple way."        
        },
        {
            "time": "2:15 PM - 2:30 PM",
            "projectId": "csse-3-215",
            "title": "NEMO App: Network Motif App",
            "studentName": "Zachary Morrison",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Wooyoung Kim",
            "posterLink": "./posters/csse/morrison_zachary.jpg",
            "abstract": "A network motif is a reoccurring statistically important subgraph pattern within a network of connected points. Network motifs are used in bioinformatics for applications such as identifying breast cancer related genes and analyzing proteins. NemoSuite, hosted on the University of Washington Bothell bioresearch website (https://bioresearch.css.uwb.edu/biores/nemo/), is a web-based tool that can analyze networks and calculate information about the graph. For my capstone, I was tasked by Professor Wooyoung to update the Nemo app, which is part of NemoSuite program, with improved functionality.\n\n To improve the functionally of the Nemo app, I was tasked with implementing new features into the backend of the Nemo website. These features included the printing of the input graph’s node, edge, and subgraph counts, the printing of a representation of each type of subgraph, and the addition of direct method calculations through the implementation of Zican Li’s direct method code (https://github.com/Kimw6/NemoLib-Java) into the current program.\n\n For my development tools, I used Apache NetBeans as my IDE, Debian for Windows subsystem for Linux to compile test versions of the program with Apache Maven, and MobaXterm to connect to and exchange files with the UW Bothell bioresearch Linux server in order to run test versions of the backend.\n\n The final version of the updated Nemolib App includes all requested features along with the original program functions. Node, edge, and subgraph count calculation and displaying have been implemented. Each of the subgraph types are now represented through the use of a chart to show connections between each point. The backend now calculates the direct mean frequency and the Ẑ - value of the input graph using Zican Li’s direct method code.\n\nOverall, I feel that this project has been significant in the development of my skills as a software engineer. It has given me the opportunity to not only obtain hands-on experience with developing code for a pre-existing software system, but also gain experience with working with web-based tools and backend development."        
        },
        {
            "time": "2:30 PM - 2:45 PM",
            "projectId": "csse-3-230",
            "title": "Amazon AWS Internship",
            "studentName": "Vandhana Prabhakaran",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Amazon",
            "facultyAdvisor": "Dr. Yusuf Pisan",
            "posterLink": "./posters/csse/Vandhana(3).jpg",
            "abstract": "Many companies are looking to transition their operations from on-premise environments to the Amazon AWS cloud due to the cost benefits and ease of scalability. During my internship at AWS in Summer 2021, we focused on making this migration process simpler. Currently, customers have to access many different Amazon services, such as Server Migration Service (SMS) and Application Migration Service, but there is no centralized tool to guide them through this migration process. The goal of my team's project is to provide customers with a single access-point to make the process as intuitive and automated as possible. Our project accomplishes this by selecting pre-defined migration scripts and executing these scripts on the customer's environment.\n\n My work on this project has been focused on the connector, which is the code that the user downloads and runs on their virtual machines. The connector handles the orchestration and execution of tasks on the customer's devices, and communicates with S3 and DynamoDB to retrieve the information on the tasks that need to be run, and executes them, while relaying the progress information back to the database to be displayed on the service account dashboard.\n\n As part of this project, I have created two Lambda functions that are accessible through API Gateway. Lambda functions are stateless and scalable pieces of code that run in response to a trigger, which in my case, is the API call. The first of these functions retrieves the list of tasks that still need to be run from DynamoDB, and the second updates the state of tasks in DynamoDB, depending on whether they have completed successfully or failed. The next phase of my project has been to incorporate my APIs into the connector, and to optimize and add features to the connector. Some of these optimizations included handling thread synchronization and thread pool allocation.\n\n As part of my internship, I worked with a variety of tools, both internal and external to Amazon, while working on this project. The Lambda functions were modeled in Smithy, written in Java, and deployed onto API Gateway using Cloud-Development Kit (CDK). I wrote the unit tests using DynamoDB Local, and the integration tests were run using Hydra and RDE.\n\n Once the connector is completed, it will be packaged with the other components and made available to AWS customers as an option to help with their migration processes."        
        },
        {
            "time": "2:45 PM - 3:00 PM",
            "projectId": "csse-3-245",
            "title": "The Shokri Report",
            "studentName": "Nick Shokri",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - T-Mobile",
            "facultyAdvisor": "Dr. Yusuf Pisan",
            "posterLink": "./posters/csse/shokri_nick.jpg",
            "abstract": "For my capstone, I worked on the Critical Reporting & Analytics team at T-Mobile. My team team’s focus was on providing reports and analysis to other T-Mobile teams. Within my team, I was a part of the inner development group that was responsible for developing and maintaining software that was used by the rest of the team. My main project was to develop a project management tool that is specific to our team’s needs and captures the statistics for each member of our team. I used SQL Server along with Python Flask to create this tool.\n\nMy team has goals that we need to meet by the end of each quarter, and there was no easy way for us to keep track of these stats for our team. The way we were doing it was manual and tedious, so we needed a way to automate the process.\n\nFirst, I introduced and developed a project management tool to track the team’s work to solve this issue. This tool also had the added benefit that my manager can use it to get an overview of what everyone on the team is doing. I chose to use Python Flask for developing the backend since it is a quick and easy framework to use. It was also one of the languages and frameworks that the other members on my team were most familiar with, so that I could easily hand it off when the internship is over. I also used SQL Server for the database to store all the information, since we needed to keep this data long-term so we would have a way to track our progress toward our quarterly goals.\n\nBy the end of the internship, I was able to get the tool deployed and started testing much earlier than the deadline. The tool ended up saving each team member ~3-5 minutes each time they need to document their work. The tool has proven to have value much above what I initially set out to accomplish, and it’s something my team will extensively use in the future. This project has taught me about agile software development and has given me a taste of what working in the industry is like."        
        },
        {
            "time": "3:00 PM - 3:15 PM",
            "projectId": "csse-3-300",
            "title": "Providing Automated Feedback on Programming Assignments",
            "studentName": "Margaret Lanphere",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Yusuf Pisan",
            "posterLink": "./posters/csse/lanphere_margaret.png",
            "abstract": "Providing feedback on code to novice programming students is critical to the development of their skills and yet professors, teaching assistants, and graders seldom have the time to provide detailed individualized feedback for each student. In this Tech for Good team research project, we built upon previous work by former member Ed Abshire to develop an automated feedback and grading system using GitHub Actions so students can improve their code prior to submission.\n\nGitHub Classroom is used to host assignment starter code and set up private student repositories.  GitHub is free and accessible for students to use and has a lot of capabilities for testing through the GitHub Actions framework. For code style evaluation, the Checkstyle and Misspell programs are run in the GitHub Actions workflow to provide feedback in the Google Java Style and catch spelling errors. Code style is important for code readability and this feedback will help students produce uniform code when developing more advanced programs. To test program correctness, general and edge case tests are written for each assignment using JUnit, a common Java unit testing framework. The workflow runs a Python script that checks for code compilation and uses the Maven build dependency tool to run the JUnit tests. A detailed test report is generated with a current score on the assignment for students to download in about a minute.\n\n Through use of this system, students can quickly test their programs for correctness and style issues to incorporate improvements, getting early practice in continuous integration. Students also get greater assurance about the grading of their program. A step-by-step tutorial and FAQ website hosted on GitHub Pages was created to help with test failures, Checkstyle warnings, and other feedback hints. This system is also helpful for instructors and graders since it provides a thorough testing framework for grading.\n\nDuring my time on this project, I worked on developing the format for the student and test repositories, GitHub Actions workflow, much of the Python script for test reports, the step-by-step tutorial with a demo assignment, and the GitHub Pages instructions website. Next quarter, this system will be used with CSS 142 students on their assignments."        
        },
        {
            "time": "3:15 PM - 3:30 PM",
            "projectId": "csse-3-315",
            "title": "T4G LeetCode Programming",
            "studentName": "Daniel Yakovlev",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Yusuf Pisan",
            "posterLink": "./posters/csse/yakovlev_daniel.png",
            "abstract": "One of the most important factors in success for Computer Science Students that are looking for internships or jobs is to be able to successfully solve coding interview questions that many companies have adopted.\n\n Computer Science students need to be proficient in several different topics such as arrays, binary trees, linked lists, dynamic programming, etc. There are several resources that are available for students to use. However, they often do not walk through the problem and how to go about solving it. Additionally, while the CS program does offer algorithm and data structure classes to cover important topics. They do not offer many problems in each topic that is needed to pass a coding interview question.\n\nThe team at T4G has gone about creating important lessons on different Computer Science topics that will further help students preparing for coding interviews. Each lesson has been grouped under a different topic that is covered and explains the problem in depth as well as explaining the multiple different approaches that can be used on a problem. This allows students to get an understanding of the different types of algorithms that can be used and build upon those they have learned through the Stepik course.\n\nAs a result, students who use the Stepik course can better understand and learn how to solve important coding interview questions as well as learning how to solve them at their own pace."        
        }
    ]
}