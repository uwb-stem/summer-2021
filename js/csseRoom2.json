{
    "csse": [
        {
            "time": "12:30 PM - 12:45 PM",
            "projectId": "csse-2-1230",
            "title": "Using Data Analysis and Machine Learning to Prevent Customer Loss",
            "studentName": "Donghee Lee",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Minds N Company",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/lee_donghee.png",
            "abstract": "I interned at a Telecom company in Korea to develop an in-house tool for the Customer Services team. Our team of developers built a tool to proactively locate customers who are possibly unsatisfied with their cellular services so that they can be provided with further care.\n\nTo achieve this, we worked together with data scientists to process data into meaningful information that can be used for machine learning applications. Specifically, my task in this project was to implement code to preprocess raw telecommunications data that generates such a dataset using python Spark API. With the application of data science and machine learning, we were able to predict the customers who are unhappy with their services early on and pass their information to the Customer Services team for problem resolution. The surveys the customers took after receiving the care indicated that 86% of them were in fact unsatisfied.\n\nThis project made an impact on the company by keeping up with the customers’ needs as well as allowing the other teams to locate the area that needs more servicing for better cellular services. In long term, this tool can greatly aid the company by maintaining the customers’ satisfaction and therefore securing the current customers and attracting new customers."        
        },
        {
            "time": "12:45 PM - 1:00 PM",
            "projectId": "csse-2-1245",
            "title": "Developing a Secure Development Lifecycle for Machine Learning Models in Adversarial Environments",
            "studentName": "Kenneth Tran",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/tran_kenneth.jpg",
            "abstract": "Secure machine learning continues to be a cat and mouse game between developers and attackers today. Rapid development of new attacks has in turn caused rapid development of new defenses for these attacks. This runs parallel to how traditional secure software development has evolved. Through the creation of processes and metrics that developers may follow, security risks are minimized and costs for an adversary to attack a system are maximized. Our goal is to provide recommendations to developers of what they can do to maximize the security of their machine learning models. This research aims to determine which hyperparameters have the greatest impact on the accuracy of a machine learning model after having experienced an evasion attack. In this context, hyperparameter is defined as a parameter, set before training, that controls the learning process of a machine learning model. An adversarial example is an instance with a small, intentional feature perturbation to cause a machine learning model to make a false prediction. An evasion attack occurs when a model is fed an adversarial example.\n\n To test each hypothesis, that each varying hyperparameter has an effect on the susceptibility of a machine learning model to evasion attacks, a framework was created such that each dataset and attack was modular. Multiple trials were done for each hyperparameter (number of iterations, learning rate, random number seed, validation accuracy, batch size, number of epochs, min/max step size), with any correlations seen in smaller datasets tested further in larger datasets against a larger variety of attacks. The results showed a weak to moderate correlation between three hyperparameters tested and model accuracy after an evasion attack: learning rate, validation accuracy, and min step size.\n\n These results suggest that learning rate, validation accuracy, and minimum step size may have an effect on the susceptibility of a machine learning model to evasion attacks. On this basis, it is hoped that this study will help inform machine learning system developers about what hyperparameters may cause greater susceptibility to such attacks."
        },
        {
            "time": "1:00 PM - 1:15 PM",
            "projectId": "csse-2-100",
            "title": "Neural Net Protection",
            "studentName": "Paul Cantrell",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/cantrell_paul.jpg",
            "abstract": "As machine learning becomes more relevant in our day-to-day lives, so too the weaknesses of it become relevant for regular people. Researchers have developed incredibly skillful neural networks, able to identify objects at above the accuracy of humans, but this feat has its caveats.\n\n Artificial neural networks have an intriguingly bizarre method of recognizing objects that leaves them susceptible to so-called “adversarial examples.” An adversarial example is a modified image that looks indistinguishable from the original to the human eye, but completely changes how the network sees it. Adversarial examples completely fool networks, leading these subtly modified inputs to produce drastically incorrect outputs. While this result may seem esoteric, manifestations of adversarial examples could be used to crash cars, among other problematic manipulations, as in the case of a nearly invisible sticker on a stop sign, causing a self-driving Tesla to now interpret the stop sign as instead a speed limit sign.\n\nThe field of research on machine learning is vast, and even the subfield of adversarial examples in machine learning has constant publications. I worked with a lab at UW Bothell to help with the long-term project of creating a secure software lifecycle, in which each stage of deployment of neural nets can be more easily examined by companies who are worried about security implications of their software.\n\n I particularly focused on aspects of the learning process that contribute to this machine learning flaw. I believe that one framing of the issue is that computers are finding it too easy to pick up on features of an image that are non-robust, and we should in some way encourage the networks away from selecting non-robust features. To this end, I employed a number of low-level computer vision techniques to make it harder for the networks to “focus in” on features that aren’t desirable.\n\n I was able to increase robustness to adversarial examples through the use of an ensemble of networks trained on these particular modifications of the input images. I hope my work here will be of value to others in the lab in pursuing good directions for the learning phase of a secure software development lifecycle. Although I think my voting technique could be part of the solution, there is still a long way to go toward developing the kind of levels of assurance we have in software engineering outside of machine learning."        
        },
        {
            "time": "1:15 PM - 1:30 PM",
            "projectId": "csse-2-115",
            "title": "T-Mobile's Provisioning",
            "studentName": "Harvy Barsoom",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - T-Mobile",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/barsoom_harvy.jpg",
            "abstract": "SPQA Provisioning is the system used in T-Mobile. My project was to make changes in the system such as generating a transaction ID which helped with the overall business logic and communication between multiple other systems. This also required creating new tables in the database to align with the transaction ID. A related task to this was also using log4j to print the transaction ID in the log statements when checking the requests made in SPQA. Some of the tools used in the project were Springboot framework, apache maven, postman, Eclipse. The micro services are written in java. Another task that I was given is changing the tables in the database used in oracle. Changes needed to be made due to the addition of the transaction ID and how it communicates with the other information in the database.  The transaction ID would have a huge impact such as reducing operational costs and look up when trying to find certain requests or information related as that when you search for a transaction ID, you find all requests made from that user’s ID and can help when trying to figure out where something went wrong in the systems with the responses. The transaction ID will also open doors to more modifications and enhancements to SPQA in the future such as when planning to move the database to Couch-base which I was a part of the process as well.  "        
        },
        {
            "time": "1:30 PM - 1:45 PM",
            "projectId": "csse-2-130",
            "title": "Technical Internship to Advance National Security",
            "studentName": "Kelvin Kam",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Sandia National Laboratories",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/kam_kelvin.png",
            "abstract": "Databases come in a lot of different sizes and shapes, and they are often specifically developed for only specific applications. In order to find a desirable database, a lot of effort must be put into research, creating sample data, coming up with a list of available database candidates that meets your requirement, and benchmarking each of the candidates. For this project, this includes performing parsing on encrypted database data into JSON format, researching into a variety of databases to create a compare and contrast table, and running candidates in docker to build a benchmark.\n\n Currently, Sandia’s satellite to ground system software uses a home-grown database for data storage, which is considered outdated with the large array of open-source databases available.The current database carries limitations ranging from its performance, reliability, and maintainability, which makes it immensely difficult for developers at Sandia to perform maintenance on the database. Therefore, it is important to replace the database with an open-source database which is easier to maintain and often offers better performance, the replacement must also meet all of the requirements specified by the satellite to ground station software.\n\nMy internship at Sandia has not officially concluded yet, therefore, I won’t be able to provide any specific result of my benchmarks. However, a docker container is created for each database candidate, and a Centos docker container is created to act as a client for each of the database candidates. Testing data is then imported into each database candidate, and a set of query, update, and commit are performed on each database.\n\nThe significance of this project is laid upon the overall modernization of Sandia’s satellite to ground system system; the result produced by this internship project will be important to future Sandia’s engineers by assisting them to select a reliable and efficient replacement database."        
        },
        {
            "time": "1:45 PM - 2:00 PM",
            "projectId": "csse-2-145",
            "title": "Mitigating Poisoning Attacks Against Federated Learning Defense Algorithms",
            "studentName": "Benjamin Birchman",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Geetha Thamilarasu",
            "posterLink": "./posters/csse/birchman_benjamin.png",
            "abstract": "Federated learning allows for vastly scaled computational resources, increasing the quality of inferences for the model. To fight against poisoning attacks (compromised updates from malicious users) against FL, several defense techniques have been applied to the FL model with varied levels of success. Common centralized machine learning defense techniques have found some success within the FL environment, but the results suffer due to the lack of regard for a FL environment. These previous defenses assume IID data which assumes no trends, fluctuations, unequal probabilities, or dependent labels within the data distribution. In FL, we cannot rely on this assumption as most applications will see variations in these trends or dependencies amon samples within the data.\n\nThis study firstly identifies the most relevant FL defense strategies that consider these pitfalls over traditional centralized learning defenses. However, a recent study demonstrates the distributed backdoor poisoning attack to be an effective strategy against these FL defenses. We propose a new defense, the Area Similarity FoolsGold (ASF) defense, that supersedes the cosine similarity implementation seen in a previous FL defense known as FoolsGold with the Triangle Area Similarity - Sector Area Similarity (TS-SS) algorithm for better identification of sybils to mitigate the effects of the DBA attack. Our solution slowed the distributed backdoor attack’s convergence for over twice the training length of other state-of-the-art FL defenses (FoolsGold and RFA) in our experiments."        
        },
        {
            "time": "2:00 PM - 2:15 PM",
            "projectId": "csse-2-200",
            "title": "Application Database Architecture Design and Development",
            "studentName": "Simon Aronsky",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Nutrieat LLC.",
            "facultyAdvisor": "Dr. Geetha Thamilarasu",
            "posterLink": "./posters/csse/aronsky_simon.PNG",
            "abstract": "At the time I joined Nutrieat, the idea, as well as much of the application design, was already created. Despite this, they were unable to move forward with the development of the nutrition tracking application because they did not have the necessary cloud infrastructure in place to manage the data. My role in the organization was to determine what tasks needed to be done in the cloud, and what tools could be used to complete them.\n\nFirst, I compared the variety of cloud service providers as to what best fit our needs. Because we required utilization of a variety of standardized computing services, the choice was Azure as it is tightly integrated with both the .NETFramework and the Visual Studio IDE.\n\nAfter making the most significant decision, which cloud host would be the foundation of our system, it became necessary to choose which variety of standardized services best fit our needs. I iterated through each, determining the superior option, including Azure SQL Database and ElasticSearch, until a final list had been assembled, which was then passed onto the rest of the team for final review.\n\nUpon agreement on our selection, I took the responsibility for implementing each of them, designing the SQL databases, the APIs, and writing the code connecting them with the user authentication service. Now we finally had the cloud services we needed to expand the application operating.\n\nThe work done through the duration of this project has been pivotal to the growth of our organization. Prior to my work, we were unable to access data outside of the client device, and had no system in place for updating product information in a seamless way.  But now, we are able to begin limited user testing amongst friends and colleagues, before we open the application for public distribution."        
        },
        {
            "time": "2:15 PM - 2:30 PM",
            "projectId": "csse-2-215",
            "title": "T-Mobile Firewall Cleanup",
            "studentName": "Carson Riland",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - T-Mobile",
            "facultyAdvisor": "Dr. Geetha Thamilarasu",
            "posterLink": "./posters/csse/riland_carson.JPG",
            "abstract": "-What was done? -\n\nOne of T-Mobile’s Bellevue Lab firewalls is currently being upgraded. Through that process I lead the cleanup on the firewall’s old policy. The tasks I completed during the cleanup consisted of:\n\n-Removing unnecessary rules that have not been hit in the past 6-months.\n\n-Removing rules with a hit count of Zero.\n\n-Adding standard T-Mobile firewall rules that are required across all T-Mobile firewalls.\n\n-Add new more specific firewall rules to take the place of overly permissive rules.\n\n-Make a process guide for future cleanups of similar firewalls w/ info on how to handle a cleanup during an upgrade to new hardware.\n\n-Why was it done? -\n\nT-Mobile has been making new standards which are being applied to all their firewalls to make them more secure, as well as improve the documentation of changes made to policies. With one of the firewalls that is part of the T-Mobile Bellevue Lab being upgraded to new hardware, it made it the perfect test example for applying the new standards and documenting the difficulties with working with old T-Mobile Firewall Policies\n\n-Results-\n\nThe measurable results that could be seen through the firewall cleanup would be a decrease in unnecessary and illegitimate traffic towards Bellevue lab through the firewall. Improved compliance to Security Assessments of security controls against firewall rules. We worked with a firewall security manager called Firemon which gives data based off how compliant rules are to security policies. Around 137 unnecessary rules were removed from the firewall. Around 8 rules were added and more may be added since I am still working with the firewall. Documentation of the cleanup process is currently being reviewed by colleagues for feedback so I can begin the final draft. I also created a communication document for informing the Bellevue Lab team of changes I was making to the firewall.\n\n-Significance-\n\nNot only did this cleanup drastically improve the security of this firewall by removing unused rules and adding standard rules, but it has also acted as a steppingstone to evaluate how T-Mobile security standards should be applied to old firewall policy. The documentation of the project can also be used for future reference when performing firewall policy cleanups of similar firewalls."        
        },
        {
            "time": "2:30 PM - 2:45 PM",
            "projectId": "csse-2-230",
            "title": "Panic Button",
            "studentName": "Antonio Yun",
            "studentMajor": "CSSE",
            "projectType": "Sponsored Internship - Seattei.com Inc",
            "facultyAdvisor": "Dr. Michael Stiber",
            "posterLink": "./posters/csse/yun_antonio.png",
            "abstract": "A new law, RCW 49.60.515, was signed in 2020 requiring hotel, motel, and retail stores that have employees working alone to have a panic button for each employee. During this internship I created a panic button that will send information to an api that will send json information to a database. I used an arduino device called the “sparkfun esp32 thing” to program the button push. The arduino board that I used allows for Wifi connections as well as BLE bluetooth connections, so I programmed the board to connect to wifi and then send a post request to an api. I then created an api that takes the panic button information and sends it to a database.\n\nI then set up a database on the company server to take in the bluetooth device that is the closest to the arduino board so that they will know the location of where the button was pushed. The panic button will allow hotels to have this panic button and be able to know the location of where the button is being pushed because of the locations of the wifi and of the BLE bluetooth devices.\n\nI have tested the product around the house and currently it only shows the closest device. What I have done is significant because the main base of the project has been finished. The main device is functional and the data gets transferred successfully to the database through the api.\n\nCurrently I have finished the programming of the board, the api, and the database. In the future, we will be testing the product at select hotels and setting up the devices in hotels to test them.\n\nI learned a lot this summer from this internship. From a coding aspect, I learned about coding with php, as well as, hosting a web server with apache. In addition, I got to see how mvc servers are made and how they function with coding. From working with others, I also learned about the time constraint within companies and I learned how to work with others when coding."        
        },
        {
            "time": "2:45 PM - 3:00 PM",
            "projectId": "csse-2-245",
            "title": "Graph-based Simluations with Graphitti",
            "studentName": "Vivek Gandhi",
            "studentMajor": "CSSE",
            "projectType": "UWB Faculty Research",
            "facultyAdvisor": "Dr. Michael Stiber",
            "posterLink": "./posters/csse/gandhi_vivek.jpg",
            "abstract": "Graphitti is a high-performance network simulator built by UW's Intelligent Networks Laboratory (INL), which is run by Dr. Michael Stiber. Graphitti is the successor to BrainGrid, which is a spiking neural network simulator with both GPU and CPU capabilities. Graphitti was created due to software rot on BrainGrid, and has the same capabilities. This gave us the opportunity to make some major design changes and bring the simulator up to modern C++ standards. Early on, we restructured the entire simulator to facilitate non-neural simulations too. A better hierarchy was defined, and the neuro-specific code was extracted from the higher levels of the codebase. The simulator is now capable to running any graph-based discrete event simulation.\n\nThe Next Generation 9-1-1 (NG-911) initiative is made to replace existing Enhanced 9-1-1 (E-911) systems. Existing systems are very complicated, and there is no uniformity across jurisdictions. Each state implements its 911 systems differently, and there is often little-to-no interoperability between neighboring jurisdictions. The primary players in the system are the caller, cell towers, PSAPs (call center that handles incoming 911 calls) and dispatchers, and responders. By defining the relations and connections between them, we can create a network that models the actual emergency response system. We used Graphitti to define these interactions and simulate the propagation of an event through this network; an event that is created by a caller, and is resolved when the caller receives a response. A good simulation will be able to recreate certain qualitative aspects of real 911 call data. This simulation can then be used to identify bad actor attacks, gauge the system's efficacy during catastrophes, or identify critical points of failure. Project sponsored by the National Security Agency under Grant Number H98230-20-1-0314."        
        },
        {
            "time": "3:00 PM - 3:15 PM",
            "projectId": "csse-2-300",
            "title": "Graphitti: Graph-Based Systems Simulator",
            "studentName": "Jordan Brown",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Michael Stiber",
            "posterLink": "./posters/csse/brown_jordan.png",
            "abstract": "Graphitti is a tool used to create custom graph-based simulations. It can run on CPU and GPU hardware to allow for easy debugging and fast execution. Graphitti’s purpose is to provide an accessible way for researchers to design and run simulations with high confidence without compromising on performance. Currently, simulations of biological neural networks and 911 call routing are supported.\n\n Graphitti is being developed by UW’s Intelligent Networks Laboratory. It is the successor to the lab’s previous neural simulator, BrainGrid. A major part of my work was done to verify consistency between the simulators, and to progress the transition from BrainGrid to Graphitti.\n\nI ensured that the simulator output of Graphitti matches that of BrainGrid, and I set up a regression testing framework to further ensure that Graphitti’s own output remains consistent as development continues. These tests consist of automated simulation runs and a command line diff of the produced output vs known good output. Any change in simulator output is reported as a failed run in GitHub Actions.\n\nI cleaned up and updated the simulator’s web-hosted documentation, fixing broken links and outdated instructions. As a complete newcomer to the project, my experience of getting acclimated to the project using available documentation allowed me to identify shortcomings in the documentation and add information that I found valuable from other sources.\n\nI also identified and fixed various bugs in the code that I uncovered during testing and normal use. These include minor output messages, restoring functionality of HDF5 file output, and correcting an inaccuracy in neural connection computations.\n\nMy contributions to Graphitti have helped ensure the ongoing accuracy and improved usability of the simulator. My work has increased functionality and improved confidence in the validity of the simulator’s output.\n\nThis capstone has given me valuable experience with integrating into an existing project and familiarizing myself with a complex code base. I learned how an organized team structures their project and executes their workflow. I also gained practical experience with Visual Studio Code, GitHub, Linux, and C++."        
        },
        {
            "time": "3:15 PM - 3:30 PM",
            "projectId": "csse-2-315",
            "title": "Improving Software Usability and Maintainability",
            "studentName": "Steven Leighton",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Michael Stiber",
            "posterLink": "./posters/csse/leighton_steven.jpg",
            "abstract": "Open-source software projects tend go through many changes over time. As a side effect, it is not uncommon for such projects to accumulate technical debt in the form of unused, redundant, or overly complex code. Until this technical debt is “repaid,” the software may become increasingly unresponsive, faulty, and difficult to modify.\n\nBrainGrid is a high-performance spiking neural network simulator which provides researchers with pre-built code that can be modified to fit different models. Workbench is a scientific workflow management tool designed to facilitate creating and running BrainGrid simulations and managing simulation artifacts. The Workbench project was originally developed as a collection of independent systems which were later combined into a single application. Because of this history, there was a significant amount of technical debt which needed to be addressed.\n\nMy project involved updating the Workbench application, specifically focusing on improving the software’s usability and maintainability. To make the project easier to understand and modify, especially for new contributors, I implemented a consistent coding standard throughout the project and added missing Javadoc comments to several classes. After carefully reviewing the existing code base, I was also able to refactor existing code to reduce complexity and improve the data model by following object oriented design principles.\n\nAnother project goal was to improve the software’s functionality to better meet the needs of users. One of the major pain points affecting user experience was that many of the files generated by the application were placed in inconvenient locations and not well organized. To address this issue, I implemented a new directory structure and provided users with the ability to choose the location of their project and simulation files.\n\nContributing to the Workbench project gave me the opportunity to work with an existing code base with an interesting history and many different contributors. This experience helped me understand the challenges associated with working on large, collaborative software projects and reinforced the importance of coding standards and software design principles."        
        }
    ]
}